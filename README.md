# DQN__DDQN__PER-DQN
**1. Intersection Environment**

A: Solving Intersection environment by Training 3 Algorithms DQN, DDQN, PER DQN for Intersection Environment. Plot the graphs for the average reward per episode, Average Q value and absolute value error.

Performing the training till convergence or 10000 episodes.

B: Evaluating the environment for 150 episodes and plotting the above mentioned metrics.

C: Comparing the results of different algorithms for the task and the performance of these alogithms. Recording the total time taken by these algorithms to train for 1000 episodes.

**2. Highway environment**

A: Solving the Highway environment by Training 3 Algorithms DQN, DDQN, PER DQN for Intersection Environment. Plotting the graphs for the average reward per episode, Average Q value and absolute value error.

Performing the training till convergence or 10000 episodes.

B: Evaluating the environment for 150 episodes and plot the above mentioned metrics.

C: Comparing the results of different algorithms for the task and the performance of these alogithms. Recording the total time taken by these algorithms to train for 1000 episodes.

D: Changing the observation mode from configuration file to Kinemetics and train DQN for 100 steps. Commenting on the change in the agent's behaviour after this process.
